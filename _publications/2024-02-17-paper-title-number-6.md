<!-- ---
title: "Deep Auto Encoder based Chatbot for Discrete Math Course"
collection: publications
category: conferences
permalink: /publication/2024-02-17-paper-title-number-4
excerpt: "Chatbots are used for the facilitation of human agents by decreasing their involvement in manually done tasks. This Chatbot is developed for students of discrete mathematics. The dataset for this experiment is accumulated from 3 books of discrete mathematics. Our model is a variant of transformer known as Bert-base-NLI-mean-tokens. Bidirectional Encoder Representations from Transformers (BERT). SBERT library is used for the generation of queryresponse embeddings. This model is fine-tuned according to our dataset and provided this model to students with android based mobile App. This model results in increase in the knowledge of students. The same approach will be implemented for other subjects as well."
date: 2022-10-20
venue: '2022 International Conference on Recent Advances in Electrical Engineering & Computer Sciences (RAEE & CS)'
paperurl: 'https://ieeexplore.ieee.org/abstract/document/9954572'
citation: 'S. Ullah, M. Liaqat, A. Asif, A. Khan, U. Aslam and H. Asif, "Deep Auto Encoder based Chatbot for Discrete Math Course," 2022 International Conference on Recent Advances in Electrical Engineering & Computer Sciences (RAEE & CS), Islamabad, Pakistan, 2022, pp. 1-7, doi: 10.1109/RAEECS56511.2022.9954572.'
---

Chatbots are used for the facilitation of human agents by decreasing their involvement in manually done tasks. This Chatbot is developed for students of discrete mathematics. The dataset for this experiment is accumulated from 3 books of discrete mathematics. Our model is a variant of transformer known as Bert-base-NLI-mean-tokens. Bidirectional Encoder Representations from Transformers (BERT). SBERT library is used for the generation of queryresponse embeddings. This model is fine-tuned according to our dataset and provided this model to students with android based mobile App. This model results in increase in the knowledge of students. The same approach will be implemented for other subjects as well.

![Gesture Detection Architecture](ThreeStepProcess.png)
*Figure 1: System architecture for YOLO-based gesture recognition.* -->



---
title: "Natural Human-Computer Interface Based on Gesture Recognition with YOLO to Enhance Virtual Lab Users’ Immersive Feeling"
collection: publications
category: conferences
permalink: /publication/2024-02-17-paper-title-number-4
excerpt: "This research focuses on advancing hand tracking and gesture recognition technologies for more intuitive human-computer interaction, particularly in virtual and augmented reality environments. Leveraging YOLO-based models, the study aims to improve user immersion through real-time gesture detection. It explores state-of-the-art techniques and proposes new algorithms to enhance accuracy and responsiveness. The developed system will be integrated into a virtual electrical power lab linked with a learning management system. Effectiveness will be assessed using pre- and post-class surveys. The project ultimately contributes to next-generation HCI by merging advanced computer vision with immersive learning environments."
date: 2024-06-23
venue: '2024 ASEE Annual Conference and Exposition Portland, Oregon, USA'
paperurl: 'https://www.researchgate.net/profile/Zhou-Zhang-10/publication/382791417_Natural_Human-Computer_Interface_Based_on_Gesture_Recognition_with_YOLO_to_Enhance_Virtual_Lab_Users'_Immersive_Feeling/links/66ace2ec8f7e1236bc327edf/Natural-Human-Computer-Interface-Based-on-Gesture-Recognition-with-YOLO-to-Enhance-Virtual-Lab-Users-Immersive-Feeling.pdf'
citation: 'Ali, M. L., & Zhang, Z. (2024, June). Natural human-computer interface based on gesture recognition with YOLO to enhance virtual lab users’ immersive feeling. Paper presented at the 2024 ASEE Annual Conference & Exposition, Portland, OR, USA'
---

This research focuses on advancing hand tracking and gesture recognition technologies for more intuitive human-computer interaction, particularly in virtual and augmented reality environments. Leveraging YOLO-based models, the study aims to improve user immersion through real-time gesture detection. It explores state-of-the-art techniques and proposes new algorithms to enhance accuracy and responsiveness. The developed system will be integrated into a virtual electrical power lab linked with a learning management system. Effectiveness will be assessed using pre- and post-class surveys. The project ultimately contributes to next-generation HCI by merging advanced computer vision with immersive learning environments.
![Gesture Detection Architecture](ThreeStepProcess.png)
*Figure 1: System architecture for YOLO-based gesture recognition.*
